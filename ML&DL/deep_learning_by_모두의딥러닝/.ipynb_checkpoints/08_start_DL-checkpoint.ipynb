{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lec 8\n",
    "\n",
    "## 딥러닝의 기본 개념\n",
    "\n",
    "뉴런은 인풋에 웨이트가 붙어 들어오고, 한곳에서 합쳐진다. 이에 bias가 붙어 아웃풋으로 빠져나가며, 어느정도의 값 이상이 되면 활성화가 되더라.\n",
    "\n",
    "여러개의 레이어를 학습할 방법이 없다며 잠시 암흑기였으나, Backpropagation이라는 방법이 생기면서 학습이 가능해졌다. 미분값을 통해 오류를 고치는 것이다.\n",
    "\n",
    "하지만 레이어가 많은 경우, backpropagation이 에러를 앞에서 뒤로 보내면서 미분값이 점점 약해지는 vanishing 문제가 생기게 된다.\n",
    "\n",
    "## 2006/2007 '딥'의 출현\n",
    "\n",
    "레이어마다 weight값이 있는데, 이 초기값을 잘 선택하면 좋다. 라는 결과를 도출한다. \n",
    "\n",
    "이러면서 다시한번 주목을 받게되고, '딥'러닝이란 말을 사용하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 08\n",
    "\n",
    "__rank__\n",
    "\n",
    "몇차원인지\n",
    "\n",
    "__shape__\n",
    "\n",
    "몇개의 element가 있는지\n",
    "\n",
    "__axis__\n",
    "\n",
    "축 (값이 클 수록 가장 안쪽에 있는 차원이다. axis = -1 은 가장 안쪽을 뜻한다.)\n",
    "\n",
    "rank에 따라 shape이 결정된다. \n",
    "\n",
    "r = 1 shape = (?)\n",
    "r = 2 shape = (?, ?)\n",
    "r = 3 shape = (?, ?, ?)\n",
    "\n",
    "tensor의 경우는 matmul을 사용해야한다. 기존의 곱하기사용은 안된다.\n",
    "\n",
    "### 브로드 캐스팅\n",
    "\n",
    "shape이 달라도 연산을 할 수 있도록 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
