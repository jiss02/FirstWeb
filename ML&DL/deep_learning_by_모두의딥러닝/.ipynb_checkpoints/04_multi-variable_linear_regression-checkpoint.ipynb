{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4강 \n",
    "\n",
    "## 4-1 여러개의 변수인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 점수예측 프로그램\n",
    "x1_data=[73., 93., 89., 96., 73.]\n",
    "x2_data=[80., 88., 91., 98., 66.]\n",
    "x3_data=[75., 93., 90., 100., 70.]\n",
    "y_data=[152., 185., 180., 196., 142.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olo51\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name = 'weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name = 'weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name = 'weight3')\n",
    "\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가설\n",
    "h = x1 * w1 + x2 * w2 + x3 * w3 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(h - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olo51\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378041.9 [-395.29266 -470.51895 -466.13736 -505.1404  -359.88028]\n",
      "2.3959007 [150.25893 185.19312 179.94717 198.42792 140.26411]\n",
      "2.3936722 [150.26411 185.19914 179.95332 198.43312 140.26993]\n",
      "2.391481 [150.2643  185.19917 179.95357 198.43187 140.27115]\n",
      "2.3893158 [150.26447 185.19919 179.9538  198.43063 140.27237]\n",
      "2.38712 [150.26466 185.19922 179.95407 198.4294  140.2736 ]\n",
      "2.3849518 [150.26485 185.19922 179.9543  198.42815 140.2748 ]\n",
      "2.382758 [150.26505 185.19923 179.95454 198.42691 140.27603]\n",
      "2.3805919 [150.26523 185.19923 179.95477 198.42566 140.27722]\n",
      "2.3784223 [150.26543 185.19925 179.955   198.42442 140.27843]\n",
      "2.3762667 [150.26562 185.19925 179.95526 198.4232  140.27963]\n",
      "2.3740895 [150.26581 185.19925 179.95549 198.42194 140.28082]\n",
      "2.371938 [150.266   185.19926 179.95573 198.42072 140.28203]\n",
      "2.3697515 [150.26624 185.19928 179.95598 198.41948 140.28323]\n",
      "2.367606 [150.26642 185.19926 179.95622 198.41824 140.28442]\n",
      "2.3654366 [150.26665 185.19928 179.95648 198.41702 140.28563]\n",
      "2.3632896 [150.26685 185.19926 179.95671 198.41577 140.28679]\n",
      "2.3611279 [150.26706 185.19926 179.95697 198.41454 140.28798]\n",
      "2.3589969 [150.26727 185.19926 179.95721 198.41333 140.28917]\n",
      "2.3568416 [150.2675  185.19926 179.95747 198.41211 140.29036]\n",
      "2.3546991 [150.26773 185.19928 179.95772 198.41089 140.29153]\n",
      "2.3525465 [150.26793 185.19925 179.95795 198.40964 140.29271]\n",
      "2.35042 [150.26816 185.19925 179.9582  198.40843 140.29388]\n",
      "2.3482692 [150.26837 185.19922 179.95845 198.40718 140.29504]\n",
      "2.3461304 [150.2686  185.19922 179.95871 198.40596 140.29622]\n",
      "2.344006 [150.26881 185.19917 179.95895 198.40472 140.29736]\n",
      "2.341874 [150.26906 185.19917 179.95918 198.40352 140.29854]\n",
      "2.3397374 [150.26929 185.19916 179.95944 198.4023  140.29971]\n",
      "2.337603 [150.26953 185.19916 179.9597  198.40108 140.30087]\n",
      "2.335483 [150.26978 185.19914 179.95998 198.39987 140.30203]\n",
      "2.3333697 [150.27    185.19911 179.96022 198.39865 140.30318]\n",
      "2.3312473 [150.27023 185.19908 179.96046 198.39743 140.30434]\n",
      "2.3291416 [150.27048 185.19907 179.96072 198.39622 140.30548]\n",
      "2.327022 [150.27072 185.19905 179.96098 198.395   140.30663]\n",
      "2.3249116 [150.27095 185.19899 179.96121 198.39378 140.30777]\n",
      "2.3227997 [150.27121 185.19899 179.96147 198.39258 140.30891]\n",
      "2.320676 [150.27147 185.19896 179.96175 198.39137 140.31007]\n",
      "2.3185894 [150.2717  185.1989  179.96199 198.39015 140.31119]\n",
      "2.31648 [150.27196 185.19888 179.96225 198.38895 140.31233]\n",
      "2.314386 [150.2722  185.19884 179.9625  198.38773 140.31345]\n",
      "2.3122983 [150.27248 185.19884 179.96278 198.38655 140.31459]\n",
      "2.310165 [150.27272 185.19876 179.963   198.3853  140.31572]\n",
      "2.308085 [150.27298 185.19875 179.96327 198.38411 140.31685]\n",
      "2.3059928 [150.27325 185.1987  179.96355 198.38292 140.31798]\n",
      "2.3038995 [150.27351 185.19867 179.96379 198.38171 140.3191 ]\n",
      "2.301826 [150.27377 185.19862 179.96407 198.38051 140.3202 ]\n",
      "2.2997537 [150.27405 185.1986  179.96432 198.37933 140.32133]\n",
      "2.2976687 [150.27429 185.19855 179.96457 198.37811 140.32245]\n",
      "2.2955925 [150.27457 185.1985  179.96484 198.37692 140.32356]\n",
      "2.2935226 [150.27483 185.19844 179.9651  198.37572 140.32466]\n",
      "2.291424 [150.27512 185.1984  179.96536 198.37451 140.32578]\n",
      "2.2893672 [150.27539 185.19836 179.96562 198.37334 140.32689]\n",
      "2.2872863 [150.27565 185.1983  179.96588 198.37212 140.32799]\n",
      "2.285226 [150.27592 185.19826 179.96614 198.37093 140.32909]\n",
      "2.2831306 [150.27621 185.1982  179.9664  198.36972 140.3302 ]\n",
      "2.2810776 [150.2765  185.19817 179.96667 198.36855 140.3313 ]\n",
      "2.2790093 [150.2768  185.1981  179.96693 198.36736 140.3324 ]\n",
      "2.2769635 [150.27707 185.19806 179.96721 198.36617 140.33348]\n",
      "2.274891 [150.27737 185.198   179.96747 198.36499 140.3346 ]\n",
      "2.2728667 [150.27763 185.19794 179.96774 198.3638  140.33566]\n",
      "2.2708077 [150.27794 185.19789 179.968   198.36263 140.33676]\n",
      "2.26875 [150.27821 185.19781 179.96826 198.36142 140.33784]\n",
      "2.2667127 [150.2785  185.19775 179.96854 198.36024 140.33893]\n",
      "2.2646563 [150.2788  185.19768 179.9688  198.35904 140.34   ]\n",
      "2.2626114 [150.2791  185.19763 179.96907 198.35786 140.34108]\n",
      "2.2605722 [150.27939 185.19756 179.96931 198.35667 140.34215]\n",
      "2.2585194 [150.2797  185.19751 179.9696  198.3555  140.34325]\n",
      "2.2564714 [150.28    185.19743 179.96988 198.35431 140.34431]\n",
      "2.2544408 [150.28029 185.19737 179.97014 198.35313 140.3454 ]\n",
      "2.252418 [150.2806  185.19728 179.9704  198.35196 140.34645]\n",
      "2.2503839 [150.28091 185.19724 179.97067 198.3508  140.34753]\n",
      "2.2483506 [150.2812  185.19716 179.97095 198.34961 140.3486 ]\n",
      "2.2463377 [150.28151 185.1971  179.97124 198.34845 140.34967]\n",
      "2.244291 [150.28181 185.197   179.97148 198.34724 140.35072]\n",
      "2.2422853 [150.28214 185.19696 179.97177 198.3461  140.35179]\n",
      "2.2402656 [150.28242 185.19687 179.97202 198.34491 140.35284]\n",
      "2.238232 [150.28276 185.19681 179.9723  198.34373 140.3539 ]\n",
      "2.2362282 [150.28305 185.19672 179.97256 198.34256 140.35495]\n",
      "2.2342205 [150.28337 185.19664 179.97284 198.3414  140.356  ]\n",
      "2.2321992 [150.28369 185.19656 179.97311 198.34023 140.35706]\n",
      "2.230188 [150.28401 185.19647 179.97339 198.33905 140.3581 ]\n",
      "2.228183 [150.28433 185.1964  179.97368 198.33789 140.35915]\n",
      "2.2261648 [150.28465 185.19632 179.97395 198.33672 140.3602 ]\n",
      "2.2241762 [150.28497 185.19624 179.97423 198.33557 140.36125]\n",
      "2.2221806 [150.2853  185.19617 179.97449 198.3344  140.36227]\n",
      "2.220159 [150.28563 185.19609 179.97478 198.33324 140.36334]\n",
      "2.2181773 [150.28595 185.19598 179.97504 198.33208 140.36436]\n",
      "2.2161784 [150.28629 185.1959  179.97531 198.33092 140.3654 ]\n",
      "2.2141805 [150.28659 185.1958  179.97559 198.32973 140.36642]\n",
      "2.2121978 [150.28693 185.19572 179.97586 198.32858 140.36746]\n",
      "2.2101967 [150.28726 185.19563 179.97615 198.32741 140.36848]\n",
      "2.208215 [150.2876  185.19554 179.97641 198.32626 140.36952]\n",
      "2.2062182 [150.28796 185.19547 179.97672 198.32513 140.37057]\n",
      "2.2042358 [150.28827 185.19536 179.97697 198.32394 140.37158]\n",
      "2.2022629 [150.2886  185.19527 179.97725 198.32278 140.37259]\n",
      "2.2002747 [150.28896 185.19518 179.97752 198.32164 140.37363]\n",
      "2.1983044 [150.28928 185.19508 179.9778  198.32048 140.37465]\n",
      "2.1963367 [150.28963 185.19498 179.97809 198.31934 140.37566]\n",
      "2.1943686 [150.28995 185.19489 179.97836 198.31818 140.37668]\n",
      "2.1923943 [150.2903  185.1948  179.97865 198.31703 140.3777 ]\n",
      "2.1904263 [150.29063 185.19469 179.97891 198.31587 140.37871]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    # 같이 기록하자\n",
    "    cost_val, hy_val, _ = sess.run([cost, h, train], feed_dict = {x1:x1_data,x2:x2_data,x3:x3_data,Y:y_data})\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(cost_val, hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 데이터의 피쳐가 많아질수록, 코드는 점점 더러워지고 스파게티 처럼 될것이다.\n",
    "\n",
    "그러니 매트릭스를 이용하여 간단하게 만들어보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[73., 80., 75.],[93., 88., 93.],[89., 91., 90],[96., 98., 100.],[73.,66.,70.,]]\n",
    "y_data=[[152.], [185.], [180.], [196.], [142.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 안의 원소의 개수는 3개인데, 데이터는 더 추가할 수 있으니 non으로!\n",
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([3,1]), name='weight') # 여기서 전치됨\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = tf.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 73841.61 [[ -89.850174]\n",
      " [-105.04847 ]\n",
      " [-105.09922 ]\n",
      " [-114.373   ]\n",
      " [ -79.304085]]\n",
      "20 0.24098678 [[151.26108]\n",
      " [184.74875]\n",
      " [180.44324]\n",
      " [196.57523]\n",
      " [141.73836]]\n",
      "40 0.24088392 [[151.26357]\n",
      " [184.75124]\n",
      " [180.44597]\n",
      " [196.57787]\n",
      " [141.74042]]\n",
      "60 0.24078941 [[151.26387]\n",
      " [184.75108]\n",
      " [180.44612]\n",
      " [196.57768]\n",
      " [141.74046]]\n",
      "80 0.2406969 [[151.26414]\n",
      " [184.75092]\n",
      " [180.44623]\n",
      " [196.57748]\n",
      " [141.74048]]\n",
      "100 0.24060564 [[151.26442]\n",
      " [184.75075]\n",
      " [180.44635]\n",
      " [196.57729]\n",
      " [141.74051]]\n",
      "120 0.2405109 [[151.2647 ]\n",
      " [184.75058]\n",
      " [180.44647]\n",
      " [196.57707]\n",
      " [141.74054]]\n",
      "140 0.24041347 [[151.26497]\n",
      " [184.75041]\n",
      " [180.44658]\n",
      " [196.57686]\n",
      " [141.74057]]\n",
      "160 0.2403179 [[151.26526]\n",
      " [184.75024]\n",
      " [180.4467 ]\n",
      " [196.57666]\n",
      " [141.7406 ]]\n",
      "180 0.2402252 [[151.26555]\n",
      " [184.75012]\n",
      " [180.44685]\n",
      " [196.57648]\n",
      " [141.74065]]\n",
      "200 0.24012478 [[151.26582]\n",
      " [184.74992]\n",
      " [180.44695]\n",
      " [196.57625]\n",
      " [141.74068]]\n",
      "220 0.24003355 [[151.2661 ]\n",
      " [184.74979]\n",
      " [180.44708]\n",
      " [196.57605]\n",
      " [141.7407 ]]\n",
      "240 0.2399435 [[151.26637]\n",
      " [184.74962]\n",
      " [180.44719]\n",
      " [196.57587]\n",
      " [141.74074]]\n",
      "260 0.23985386 [[151.26665]\n",
      " [184.74945]\n",
      " [180.44733]\n",
      " [196.57567]\n",
      " [141.74078]]\n",
      "280 0.23975691 [[151.26692]\n",
      " [184.74928]\n",
      " [180.44743]\n",
      " [196.57545]\n",
      " [141.74081]]\n",
      "300 0.23966666 [[151.2672 ]\n",
      " [184.74913]\n",
      " [180.44756]\n",
      " [196.57527]\n",
      " [141.74086]]\n",
      "320 0.2395695 [[151.26747]\n",
      " [184.749  ]\n",
      " [180.44768]\n",
      " [196.57506]\n",
      " [141.74089]]\n",
      "340 0.23948343 [[151.26773]\n",
      " [184.74883]\n",
      " [180.4478 ]\n",
      " [196.57486]\n",
      " [141.74092]]\n",
      "360 0.23938672 [[151.268  ]\n",
      " [184.74866]\n",
      " [180.4479 ]\n",
      " [196.57465]\n",
      " [141.74095]]\n",
      "380 0.23930041 [[151.26826]\n",
      " [184.7485 ]\n",
      " [180.44804]\n",
      " [196.57445]\n",
      " [141.741  ]]\n",
      "400 0.23920853 [[151.26854]\n",
      " [184.74835]\n",
      " [180.44817]\n",
      " [196.57425]\n",
      " [141.74103]]\n",
      "420 0.23910908 [[151.26883]\n",
      " [184.7482 ]\n",
      " [180.44829]\n",
      " [196.57405]\n",
      " [141.74109]]\n",
      "440 0.23901713 [[151.26909]\n",
      " [184.74803]\n",
      " [180.4484 ]\n",
      " [196.57384]\n",
      " [141.74112]]\n",
      "460 0.23892835 [[151.26935]\n",
      " [184.7479 ]\n",
      " [180.44852]\n",
      " [196.57364]\n",
      " [141.74115]]\n",
      "480 0.2388351 [[151.26962]\n",
      " [184.74773]\n",
      " [180.44864]\n",
      " [196.57344]\n",
      " [141.74121]]\n",
      "500 0.23874798 [[151.26988]\n",
      " [184.74757]\n",
      " [180.44876]\n",
      " [196.57324]\n",
      " [141.74124]]\n",
      "520 0.23865493 [[151.27016]\n",
      " [184.74742]\n",
      " [180.44888]\n",
      " [196.57304]\n",
      " [141.74129]]\n",
      "540 0.23856011 [[151.27042]\n",
      " [184.74727]\n",
      " [180.44899]\n",
      " [196.57283]\n",
      " [141.74133]]\n",
      "560 0.23847175 [[151.27066]\n",
      " [184.74713]\n",
      " [180.4491 ]\n",
      " [196.57263]\n",
      " [141.74138]]\n",
      "580 0.2383804 [[151.27094]\n",
      " [184.74696]\n",
      " [180.44922]\n",
      " [196.57243]\n",
      " [141.74142]]\n",
      "600 0.23828599 [[151.27121]\n",
      " [184.74683]\n",
      " [180.44934]\n",
      " [196.57224]\n",
      " [141.74147]]\n",
      "620 0.2381961 [[151.27147]\n",
      " [184.74667]\n",
      " [180.44946]\n",
      " [196.57204]\n",
      " [141.74153]]\n",
      "640 0.2381076 [[151.27171]\n",
      " [184.74652]\n",
      " [180.44957]\n",
      " [196.57182]\n",
      " [141.74156]]\n",
      "660 0.23801784 [[151.27197]\n",
      " [184.74638]\n",
      " [180.44969]\n",
      " [196.57162]\n",
      " [141.74161]]\n",
      "680 0.2379281 [[151.27223]\n",
      " [184.74623]\n",
      " [180.44981]\n",
      " [196.57143]\n",
      " [141.74167]]\n",
      "700 0.23783883 [[151.27249]\n",
      " [184.74608]\n",
      " [180.44992]\n",
      " [196.57123]\n",
      " [141.7417 ]]\n",
      "720 0.23774108 [[151.27275]\n",
      " [184.74593]\n",
      " [180.45003]\n",
      " [196.571  ]\n",
      " [141.74174]]\n",
      "740 0.23765321 [[151.273  ]\n",
      " [184.74579]\n",
      " [180.45013]\n",
      " [196.5708 ]\n",
      " [141.74179]]\n",
      "760 0.23756394 [[151.27327]\n",
      " [184.74564]\n",
      " [180.45027]\n",
      " [196.57062]\n",
      " [141.74187]]\n",
      "780 0.23747429 [[151.27351]\n",
      " [184.7455 ]\n",
      " [180.45038]\n",
      " [196.5704 ]\n",
      " [141.7419 ]]\n",
      "800 0.23738214 [[151.27377]\n",
      " [184.74535]\n",
      " [180.45049]\n",
      " [196.5702 ]\n",
      " [141.74196]]\n",
      "820 0.23729262 [[151.27402]\n",
      " [184.7452 ]\n",
      " [180.45059]\n",
      " [196.56999]\n",
      " [141.742  ]]\n",
      "840 0.23720336 [[151.27428]\n",
      " [184.74506]\n",
      " [180.45071]\n",
      " [196.5698 ]\n",
      " [141.74205]]\n",
      "860 0.23711741 [[151.27452]\n",
      " [184.7449 ]\n",
      " [180.45082]\n",
      " [196.5696 ]\n",
      " [141.7421 ]]\n",
      "880 0.23702669 [[151.27478]\n",
      " [184.74477]\n",
      " [180.45094]\n",
      " [196.5694 ]\n",
      " [141.74216]]\n",
      "900 0.23693423 [[151.27502]\n",
      " [184.74463]\n",
      " [180.45105]\n",
      " [196.56918]\n",
      " [141.74222]]\n",
      "920 0.23684244 [[151.27528]\n",
      " [184.74449]\n",
      " [180.45116]\n",
      " [196.56898]\n",
      " [141.74226]]\n",
      "940 0.23675504 [[151.27554]\n",
      " [184.74434]\n",
      " [180.45128]\n",
      " [196.56879]\n",
      " [141.74231]]\n",
      "960 0.23667184 [[151.27577]\n",
      " [184.74422]\n",
      " [180.4514 ]\n",
      " [196.56859]\n",
      " [141.74237]]\n",
      "980 0.23658332 [[151.27603]\n",
      " [184.74405]\n",
      " [180.4515 ]\n",
      " [196.56839]\n",
      " [141.74242]]\n",
      "1000 0.23648986 [[151.27629]\n",
      " [184.74393]\n",
      " [180.45163]\n",
      " [196.56819]\n",
      " [141.7425 ]]\n",
      "1020 0.23640084 [[151.27654]\n",
      " [184.74377]\n",
      " [180.45174]\n",
      " [196.56798]\n",
      " [141.74254]]\n",
      "1040 0.23631823 [[151.27676]\n",
      " [184.74364]\n",
      " [180.45184]\n",
      " [196.56778]\n",
      " [141.74258]]\n",
      "1060 0.23622338 [[151.27702]\n",
      " [184.74348]\n",
      " [180.45195]\n",
      " [196.56757]\n",
      " [141.74265]]\n",
      "1080 0.23613581 [[151.27725]\n",
      " [184.74335]\n",
      " [180.45206]\n",
      " [196.56735]\n",
      " [141.7427 ]]\n",
      "1100 0.23605244 [[151.2775 ]\n",
      " [184.74321]\n",
      " [180.45216]\n",
      " [196.56717]\n",
      " [141.74275]]\n",
      "1120 0.2359577 [[151.27776]\n",
      " [184.74309]\n",
      " [180.45229]\n",
      " [196.56697]\n",
      " [141.74284]]\n",
      "1140 0.235864 [[151.278  ]\n",
      " [184.74295]\n",
      " [180.4524 ]\n",
      " [196.56674]\n",
      " [141.74289]]\n",
      "1160 0.23578326 [[151.27823]\n",
      " [184.7428 ]\n",
      " [180.4525 ]\n",
      " [196.56654]\n",
      " [141.74294]]\n",
      "1180 0.23569465 [[151.27847]\n",
      " [184.74268]\n",
      " [180.45262]\n",
      " [196.56635]\n",
      " [141.74301]]\n",
      "1200 0.2356065 [[151.27872]\n",
      " [184.74254]\n",
      " [180.45273]\n",
      " [196.56615]\n",
      " [141.74307]]\n",
      "1220 0.23552279 [[151.27895]\n",
      " [184.7424 ]\n",
      " [180.45284]\n",
      " [196.56595]\n",
      " [141.74313]]\n",
      "1240 0.23543563 [[151.27917]\n",
      " [184.74226]\n",
      " [180.45294]\n",
      " [196.56573]\n",
      " [141.7432 ]]\n",
      "1260 0.23534444 [[151.27943]\n",
      " [184.74214]\n",
      " [180.45306]\n",
      " [196.56554]\n",
      " [141.74326]]\n",
      "1280 0.23526084 [[151.27966]\n",
      " [184.742  ]\n",
      " [180.45317]\n",
      " [196.56534]\n",
      " [141.74332]]\n",
      "1300 0.23517136 [[151.2799 ]\n",
      " [184.74187]\n",
      " [180.45328]\n",
      " [196.56514]\n",
      " [141.7434 ]]\n",
      "1320 0.2350879 [[151.28014]\n",
      " [184.74173]\n",
      " [180.45338]\n",
      " [196.56494]\n",
      " [141.74345]]\n",
      "1340 0.23498914 [[151.2804 ]\n",
      " [184.74161]\n",
      " [180.45349]\n",
      " [196.56473]\n",
      " [141.74353]]\n",
      "1360 0.23491172 [[151.28061]\n",
      " [184.74147]\n",
      " [180.4536 ]\n",
      " [196.56453]\n",
      " [141.74358]]\n",
      "1380 0.23482342 [[151.28084]\n",
      " [184.74133]\n",
      " [180.4537 ]\n",
      " [196.56432]\n",
      " [141.74365]]\n",
      "1400 0.23473673 [[151.28107]\n",
      " [184.7412 ]\n",
      " [180.45381]\n",
      " [196.5641 ]\n",
      " [141.74371]]\n",
      "1420 0.23464635 [[151.28131]\n",
      " [184.74106]\n",
      " [180.4539 ]\n",
      " [196.5639 ]\n",
      " [141.74377]]\n",
      "1440 0.23456755 [[151.28152]\n",
      " [184.74094]\n",
      " [180.45401]\n",
      " [196.5637 ]\n",
      " [141.74382]]\n",
      "1460 0.23447628 [[151.28177]\n",
      " [184.74081]\n",
      " [180.45413]\n",
      " [196.56349]\n",
      " [141.7439 ]]\n",
      "1480 0.23439665 [[151.282  ]\n",
      " [184.74068]\n",
      " [180.45424]\n",
      " [196.56331]\n",
      " [141.74396]]\n",
      "1500 0.23430733 [[151.28224]\n",
      " [184.74055]\n",
      " [180.45436]\n",
      " [196.56311]\n",
      " [141.74405]]\n",
      "1520 0.23421817 [[151.28247]\n",
      " [184.74042]\n",
      " [180.45445]\n",
      " [196.5629 ]\n",
      " [141.74411]]\n",
      "1540 0.23413844 [[151.28268]\n",
      " [184.74028]\n",
      " [180.45454]\n",
      " [196.5627 ]\n",
      " [141.74416]]\n",
      "1560 0.23404714 [[151.28291]\n",
      " [184.74014]\n",
      " [180.45465]\n",
      " [196.56247]\n",
      " [141.74423]]\n",
      "1580 0.23395868 [[151.28316]\n",
      " [184.74004]\n",
      " [180.45476]\n",
      " [196.56229]\n",
      " [141.74431]]\n",
      "1600 0.2338725 [[151.28339]\n",
      " [184.7399 ]\n",
      " [180.45486]\n",
      " [196.56207]\n",
      " [141.74437]]\n",
      "1620 0.23378937 [[151.28362]\n",
      " [184.73979]\n",
      " [180.45499]\n",
      " [196.56187]\n",
      " [141.74443]]\n",
      "1640 0.23370679 [[151.28383]\n",
      " [184.73965]\n",
      " [180.45508]\n",
      " [196.56168]\n",
      " [141.7445 ]]\n",
      "1660 0.2336226 [[151.28406]\n",
      " [184.73952]\n",
      " [180.45518]\n",
      " [196.56148]\n",
      " [141.74458]]\n",
      "1680 0.23353848 [[151.28429]\n",
      " [184.7394 ]\n",
      " [180.45529]\n",
      " [196.56128]\n",
      " [141.74464]]\n",
      "1700 0.23345189 [[151.2845 ]\n",
      " [184.73927]\n",
      " [180.4554 ]\n",
      " [196.56105]\n",
      " [141.7447 ]]\n",
      "1720 0.23336379 [[151.28474]\n",
      " [184.73915]\n",
      " [180.4555 ]\n",
      " [196.56087]\n",
      " [141.7448 ]]\n",
      "1740 0.23328575 [[151.28496]\n",
      " [184.73901]\n",
      " [180.45561]\n",
      " [196.56067]\n",
      " [141.74486]]\n",
      "1760 0.23319404 [[151.28519]\n",
      " [184.73889]\n",
      " [180.4557 ]\n",
      " [196.56046]\n",
      " [141.74493]]\n",
      "1780 0.23310673 [[151.28542]\n",
      " [184.73877]\n",
      " [180.45581]\n",
      " [196.56024]\n",
      " [141.745  ]]\n",
      "1800 0.2330273 [[151.28563]\n",
      " [184.73863]\n",
      " [180.45592]\n",
      " [196.56004]\n",
      " [141.74507]]\n",
      "1820 0.23294035 [[151.28586]\n",
      " [184.73853]\n",
      " [180.45602]\n",
      " [196.55984]\n",
      " [141.74515]]\n",
      "1840 0.23285937 [[151.28607]\n",
      " [184.7384 ]\n",
      " [180.45613]\n",
      " [196.55965]\n",
      " [141.74522]]\n",
      "1860 0.23277411 [[151.2863 ]\n",
      " [184.73828]\n",
      " [180.45624]\n",
      " [196.55945]\n",
      " [141.7453 ]]\n",
      "1880 0.23268867 [[151.28651]\n",
      " [184.73814]\n",
      " [180.45633]\n",
      " [196.55923]\n",
      " [141.74538]]\n",
      "1900 0.23260286 [[151.28673]\n",
      " [184.73804]\n",
      " [180.45644]\n",
      " [196.55902]\n",
      " [141.74545]]\n",
      "1920 0.23252077 [[151.28696]\n",
      " [184.73793]\n",
      " [180.45656]\n",
      " [196.55884]\n",
      " [141.74554]]\n",
      "1940 0.23243585 [[151.28717]\n",
      " [184.73778]\n",
      " [180.45663]\n",
      " [196.55862]\n",
      " [141.7456 ]]\n",
      "1960 0.23235357 [[151.28738]\n",
      " [184.73767]\n",
      " [180.45674]\n",
      " [196.55843]\n",
      " [141.74568]]\n",
      "1980 0.23226678 [[151.2876 ]\n",
      " [184.73755]\n",
      " [180.45683]\n",
      " [196.55821]\n",
      " [141.74576]]\n",
      "2000 0.23218623 [[151.28781]\n",
      " [184.73743]\n",
      " [180.45694]\n",
      " [196.55801]\n",
      " [141.74583]]\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.square(hy - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    # 같이 기록하자\n",
    "    cost_val, hy_val, _ = sess.run([cost, hy, train], feed_dict = {X:x_data,Y:y_data})\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('04score.csv', delimiter=',', dtype = np.float32, skiprows = 1)\n",
    "x_data = xy[:, 0:-1] # 처음부터 끝의 한자리 뺀 것 까지 자른다.\n",
    "y_data = xy[:,[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3) [[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]] 6\n",
      "(6, 1) [[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_data.shape, x_data, len(x_data))\n",
    "print(y_data.shape, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olo51\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape = [None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "# 나가는 값이 y에 맞춰준다. 1개니까 1임.\n",
    "w = tf.Variable(tf.random_normal([3,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = tf.matmul(X, w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(hy-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "    [cost, hy, train], feed_dict = {X: x_data, Y: y_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189.01064]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(hy,feed_dict={X:[[100,70,101]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파일이 굉장히 커져서 메모리에도 올리기 힘들면 어떡할까?\n",
    "\n",
    "numpy로 파일이 올라가지 않을 것이다.\n",
    "\n",
    "이를 해결하기위해 텐서플로에서는 queue runner라는 것을 제공한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러개의 파일을 큐에 쌓고 리더로 연결해서 디코더-`,`를 분리한다던가-를 한다.\n",
    "\n",
    "몇개의 배치만큼 읽어와서 학습을 시켜주니 아주 편리하다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__예제 코드__\n",
    "\n",
    "```python\n",
    "# 파일들을 리스트 업 한다.\n",
    "filename_queue = tf.train.string_input_producer([filename1, fn2, ...], shuffle = False, name = 'filename_queue')\n",
    "\n",
    "# 파일을 읽어올 리더를 정의해준다.\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# 값을 읽었는데, 이를 어떻게 파싱할 것인가?\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "\n",
    "# 값의 디폴트타입을 정의해줄 수 있다. \n",
    "xy = tf.decode_csv(value, record_defaluts = record_defaults)\n",
    "```\n",
    "\n",
    "__배치__\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# 배치를 가져올 수 있게해주며, 한번에 몇개씩 가져올 건지 알려줄 수 있다.\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    # x_batch, y_batch를 feed_dict로 넣어주면 될 것이다.\n",
    "    ...\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "\n",
    "print(sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
