{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6강\n",
    "\n",
    "스코어를 소프트맥스라는 함수에 통과시켜 확률처럼 사용하게 해준다.\n",
    "\n",
    "> 어떤 레이블인가에대한 확률로 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder('float', [None, 4])\n",
    "y = tf.placeholder('float', [None, 3]) # 원핫일때, 레이블의 갯수이다.\n",
    "nb_classes = 3\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name = 'bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(x, W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\olo51\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(-tf.reduce_sum(y * tf.log(hypothesis), axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate= 0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.3460183\n",
      "--------------\n",
      "[[4.4644311e-01 1.7510966e-10 5.5355692e-01]] [2]\n",
      "--------------\n",
      "[[9.063399e-01 8.685963e-05 9.357320e-02]] [0]\n",
      "--------------\n",
      "[[0.01338154 0.01340834 0.9732101 ]] [2]\n",
      "--------------\n",
      "[[4.4644311e-01 1.7510966e-10 5.5355692e-01]\n",
      " [9.0633988e-01 8.6859633e-05 9.3573198e-02]\n",
      " [1.3381543e-02 1.3408344e-02 9.7321010e-01]] [2 0 2]\n",
      "200 0.45783472\n",
      "--------------\n",
      "[[0.01859414 0.97922486 0.00218105]] [1]\n",
      "--------------\n",
      "[[0.63675624 0.31232616 0.0509176 ]] [0]\n",
      "--------------\n",
      "[[6.4569648e-04 3.9473809e-02 9.5988053e-01]] [2]\n",
      "--------------\n",
      "[[1.8594144e-02 9.7922486e-01 2.1810518e-03]\n",
      " [6.3675624e-01 3.1232616e-01 5.0917592e-02]\n",
      " [6.4569648e-04 3.9473809e-02 9.5988053e-01]] [1 0 2]\n",
      "400 0.36584038\n",
      "--------------\n",
      "[[9.3054511e-03 9.9034661e-01 3.4797087e-04]] [1]\n",
      "--------------\n",
      "[[0.70400316 0.25445467 0.04154212]] [0]\n",
      "--------------\n",
      "[[8.0498576e-05 1.7740462e-02 9.8217899e-01]] [2]\n",
      "--------------\n",
      "[[9.3054501e-03 9.9034661e-01 3.4797087e-04]\n",
      " [7.0400316e-01 2.5445467e-01 4.1542120e-02]\n",
      " [8.0498568e-05 1.7740462e-02 9.8217899e-01]] [1 0 2]\n",
      "600 0.286713\n",
      "--------------\n",
      "[[7.9842787e-03 9.9187344e-01 1.4226844e-04]] [1]\n",
      "--------------\n",
      "[[0.7845763  0.18529567 0.03012802]] [0]\n",
      "--------------\n",
      "[[1.4434887e-05 8.3485255e-03 9.9163705e-01]] [2]\n",
      "--------------\n",
      "[[7.9842787e-03 9.9187344e-01 1.4226844e-04]\n",
      " [7.8457630e-01 1.8529567e-01 3.0128021e-02]\n",
      " [1.4434887e-05 8.3485255e-03 9.9163705e-01]] [1 0 2]\n",
      "800 0.23785049\n",
      "--------------\n",
      "[[1.1348783e-02 9.8854768e-01 1.0354338e-04]] [1]\n",
      "--------------\n",
      "[[0.85922265 0.12006254 0.02071477]] [0]\n",
      "--------------\n",
      "[[3.5064975e-06 4.0696091e-03 9.9592680e-01]] [2]\n",
      "--------------\n",
      "[[1.1348783e-02 9.8854768e-01 1.0354338e-04]\n",
      " [8.5922265e-01 1.2006254e-01 2.0714771e-02]\n",
      " [3.5064975e-06 4.0696091e-03 9.9592680e-01]] [1 0 2]\n",
      "1000 0.21442531\n",
      "--------------\n",
      "[[7.0265280e-03 9.9291611e-01 5.7448036e-05]] [1]\n",
      "--------------\n",
      "[[0.8797164  0.10426812 0.01601554]] [0]\n",
      "--------------\n",
      "[[9.6842462e-07 2.2661553e-03 9.9773288e-01]] [2]\n",
      "--------------\n",
      "[[7.0265280e-03 9.9291611e-01 5.7448033e-05]\n",
      " [8.7971640e-01 1.0426812e-01 1.6015541e-02]\n",
      " [9.6842462e-07 2.2661553e-03 9.9773288e-01]] [1 0 2]\n",
      "1200 0.19524686\n",
      "--------------\n",
      "[[4.4563287e-03 9.9550855e-01 3.5073474e-05]] [1]\n",
      "--------------\n",
      "[[0.8967494  0.09065273 0.01259782]] [0]\n",
      "--------------\n",
      "[[3.0118466e-07 1.3551456e-03 9.9864453e-01]] [2]\n",
      "--------------\n",
      "[[4.4563287e-03 9.9550855e-01 3.5073474e-05]\n",
      " [8.9674938e-01 9.0652727e-02 1.2597815e-02]\n",
      " [3.0118466e-07 1.3551456e-03 9.9864453e-01]] [1 0 2]\n",
      "1400 0.17919889\n",
      "--------------\n",
      "[[2.8963070e-03 9.9708086e-01 2.2825048e-05]] [1]\n",
      "--------------\n",
      "[[0.91101915 0.07893547 0.0100454 ]] [0]\n",
      "--------------\n",
      "[[1.0339597e-07 8.5612480e-04 9.9914372e-01]] [2]\n",
      "--------------\n",
      "[[2.8963070e-03 9.9708086e-01 2.2825048e-05]\n",
      " [9.1101915e-01 7.8935467e-02 1.0045395e-02]\n",
      " [1.0339597e-07 8.5612480e-04 9.9914372e-01]] [1 0 2]\n",
      "1600 0.16555405\n",
      "--------------\n",
      "[[1.9258666e-03 9.9805850e-01 1.5573789e-05]] [1]\n",
      "--------------\n",
      "[[0.92299545 0.06889825 0.00810636]] [0]\n",
      "--------------\n",
      "[[3.8588507e-08 5.6506478e-04 9.9943489e-01]] [2]\n",
      "--------------\n",
      "[[1.9258666e-03 9.9805850e-01 1.5573789e-05]\n",
      " [9.2299545e-01 6.8898246e-02 8.1063565e-03]\n",
      " [3.8588507e-08 5.6506478e-04 9.9943489e-01]] [1 0 2]\n",
      "1800 0.15380497\n",
      "--------------\n",
      "[[1.3079557e-03 9.9868101e-01 1.1026156e-05]] [1]\n",
      "--------------\n",
      "[[0.9330703  0.0603179  0.00661182]] [0]\n",
      "--------------\n",
      "[[1.5471626e-08 3.8655745e-04 9.9961346e-01]] [2]\n",
      "--------------\n",
      "[[1.3079557e-03 9.9868101e-01 1.1026156e-05]\n",
      " [9.3307030e-01 6.0317904e-02 6.6118194e-03]\n",
      " [1.5471626e-08 3.8655748e-04 9.9961346e-01]] [1 0 2]\n",
      "2000 0.14358187\n",
      "--------------\n",
      "[[9.0578914e-04 9.9908614e-01 8.0436184e-06]] [1]\n",
      "--------------\n",
      "[[0.94157094 0.05298383 0.00544518]] [0]\n",
      "--------------\n",
      "[[6.6010921e-09 2.7247737e-04 9.9972755e-01]] [2]\n",
      "--------------\n",
      "[[9.0578909e-04 9.9908614e-01 8.0436184e-06]\n",
      " [9.4157094e-01 5.2983828e-02 5.4451786e-03]\n",
      " [6.6010921e-09 2.7247737e-04 9.9972755e-01]] [1 0 2]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(2001):\n",
    "        sess.run(optimizer, feed_dict = {x:x_data, y:y_data})\n",
    "        if step % 200 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = {x:x_data, y:y_data}))\n",
    "            print('--------------')\n",
    "    # Testing & One-hot encoding\n",
    "            a = sess.run(hypothesis, feed_dict={x: [[1, 11, 7, 9]]})\n",
    "            print(a, sess.run(tf.argmax(a, 1)))\n",
    "\n",
    "            print('--------------')\n",
    "            b = sess.run(hypothesis, feed_dict={x: [[1, 3, 4, 3]]})\n",
    "            print(b, sess.run(tf.argmax(b, 1)))\n",
    "\n",
    "            print('--------------')\n",
    "            c = sess.run(hypothesis, feed_dict={x: [[1, 1, 0, 1]]})\n",
    "            print(c, sess.run(tf.argmax(c, 1)))\n",
    "\n",
    "            print('--------------')\n",
    "            all = sess.run(hypothesis, feed_dict={x: [[1, 11, 7, 9], [1, 3, 4, 3], [1, 1, 0, 1]]})\n",
    "            print(all, sess.run(tf.argmax(all, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__arg_max(데이터, (axis에서의 최강자를뽑아주세요)축)__\n",
    "\n",
    "가장 큰 값을 골라서 인덱스를 리턴해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fancy하게 softmax를 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('data/data-04-zoo.csv', delimiter = ',', dtype = np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# 7가지 종으로 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원핫으로 바꾸어준다.\n",
    "nb_classes = 7\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 16])\n",
    "Y = tf.placeholder(tf.int32, [None, 1])  # 0 ~ 6\n",
    "\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes) # 아웃풋이 n+1차원으로 나온다.\n",
    "# 그래서 (?, 7)로 해줘야한다. -1은 everything\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([16, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "logits = tf.matmul(X, W) + b\n",
    "hypothesis = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"ArgMax_887:0\", shape=(?,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                                                 labels=Y_one_hot))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# 확률을 0~6사이의 값중 하나로 만들어 낸다. \n",
    "# 가장 큰 값의 인덱스 반환.\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "# 실제의 값과 예측값 비교.\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))\n",
    "# 맞는 것들 평균낸다.\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 1)\n",
      "Step: 0\tCost: 5.701645851135254\tAcc: 0.0891089141368866\n",
      "Step: 100\tCost: 0.7376276850700378\tAcc: 0.8613861203193665\n",
      "Step: 200\tCost: 0.48127636313438416\tAcc: 0.8910890817642212\n",
      "Step: 300\tCost: 0.35100501775741577\tAcc: 0.9009901285171509\n",
      "Step: 400\tCost: 0.27868667244911194\tAcc: 0.9306930899620056\n",
      "Step: 500\tCost: 0.23379281163215637\tAcc: 0.9504950642585754\n",
      "Step: 600\tCost: 0.20194265246391296\tAcc: 0.9603960514068604\n",
      "Step: 700\tCost: 0.1775452196598053\tAcc: 0.9603960514068604\n",
      "Step: 800\tCost: 0.15805691480636597\tAcc: 0.9801980257034302\n",
      "Step: 900\tCost: 0.1420888751745224\tAcc: 0.9801980257034302\n",
      "Step: 1000\tCost: 0.12877796590328217\tAcc: 0.9801980257034302\n",
      "Step: 1100\tCost: 0.1175382137298584\tAcc: 0.9801980257034302\n",
      "Step: 1200\tCost: 0.10794739425182343\tAcc: 0.9900990128517151\n",
      "Step: 1300\tCost: 0.09968928247690201\tAcc: 0.9900990128517151\n",
      "Step: 1400\tCost: 0.09252102673053741\tAcc: 1.0\n",
      "Step: 1500\tCost: 0.08625277876853943\tAcc: 1.0\n",
      "Step: 1600\tCost: 0.08073440194129944\tAcc: 1.0\n",
      "Step: 1700\tCost: 0.07584567368030548\tAcc: 1.0\n",
      "Step: 1800\tCost: 0.07148982584476471\tAcc: 1.0\n",
      "Step: 1900\tCost: 0.06758809089660645\tAcc: 1.0\n",
      "Step: 2000\tCost: 0.06407584995031357\tAcc: 1.0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(y_data.shape)\n",
    "    for step in range(2001):\n",
    "        _, cost_val, acc_val = sess.run([optimizer, cost, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "                                        \n",
    "        if step % 100 == 0:\n",
    "            print(\"Step: {}\\tCost: {}\\tAcc: {}\".format(step, cost_val, acc_val))\n",
    "\n",
    "    # Let's see if we can predict\n",
    "    pred = sess.run(prediction, feed_dict={X: x_data})\n",
    "    # y_data: (N,1) = flatten => (N, ) matches pred.shape. 평평하게 해준다는 거다.\n",
    "    for p, y in zip(pred, y_data.flatten()):\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p == int(y), p, int(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
